import random
import wandb
import yaml
import tqdm
import argparse
import time
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.distributed as dist
from itertools import cycle
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from monai.transforms import *
from config.experiment import prepare_experiment, update_config_file, makedirs
from models.segmentation_models import SemiSupervisedContrastiveSegmentationModelA, SemiSupervisedContrastiveSegmentationModelB
from utils.iteration.load_data_v2 import TrainValDataPipeline
from utils.iteration.iterator import set_random_seed
from utils.ddp_utils import init_distributed_mode
from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler
from utils.function import plot_train_losses,plot_accuracy,plot_val_losses
from utils.earlystopping import *
from utils.earlystopping import EpochManager
torch.multiprocessing.set_sharing_strategy('file_system')

def parse_args():
    # torch.backends.cudnn.benchmark = True
    parser = argparse.ArgumentParser()
    parser.add_argument('--task', type=str, default='la',
                        help='experiment task, currently support "acdc","pancreas", "la" "BraTS2020"')
    parser.add_argument('--eval_interval', type=int, default=5, help='interval for evaluation')
    parser.add_argument('--save_interval', type=int, default=10, help='interval for checkpoint saving')
    parser.add_argument('--mixed', action="store_true",
                        help='whether to use PyTorch native mixed precision training')
    parser.add_argument('-pc', '--pretrain_ckpt', type=str, help='model checkpoint used for fine tuning')
    parser.add_argument('--benchmark', action="store_true",
                        help='whether to use cudnn benchmark to speed up convolution operations')
    parser.add_argument('--ncpu', type=int, default=8, help='number of workers for dataloader')
    parser.add_argument('--verbose', action='store_true',default='verbose', help='print progress bar while training')
    parser.add_argument('--exp_name', type=str, default='running', help='experiment name to save logs')
    parser.add_argument('--debug', action="store_true", help='enable debug mode')
    parser.add_argument('--wandb', action='store_true', help='use WandB for experiment logging')
    parser.add_argument('--entity', type=str, help='WandB entity when logging')
    parser.add_argument("--world-size", default=1, type=int, help="number of distributed processes")
    parser.add_argument("--dist-url", default="env://", type=str, help="url used to set up distributed training")
    return parser.parse_args()

def main():
    args = parse_args()
    ngpu = torch.cuda.device_count()
    init_distributed_mode(args)
    # load the cfg file
    cfg_file = 'configs/{}.cfg'.format(args.task)
    with open(cfg_file, 'r') as f:
        cfg = yaml.safe_load(f)
        print("successfully loaded config file: ", cfg)
    # update task-specific configurations
    cfg = update_config_file(args, cfg)
    # set important hyper-parameters
    seed = cfg['TRAIN']['SEED']  # random seed
    batch_size = cfg['TRAIN']['BATCHSIZE']  # batch size
    num_epochs = cfg['TRAIN']['EPOCHS']  # number of epochs
    ratio = cfg['TRAIN']['RATIO']  # the ratio of labeled images in the training dataset, ignored for task 'tbi'
    # define experiment name
    full_exp_name = args.exp_name + '-task_{}-ratio_{}'.format(args.task, ratio)
    cfg['EXP_NAME'] = full_exp_name

    # pretrain_ckpt = '/root/autodl-tmp/DBCPS/DBCPS/experiments/checkpoints//running-task_la-ratio_0.2/Epoch_100.pkl'

    if args.debug:
        num_epochs = 2
    # set random seed for reproductivity
    set_random_seed(seed=seed, benchmark=args.benchmark)

    # define training & validation transforms
    train_aug = Compose([
        LoadImaged(keys=['image', 'label'], allow_missing_keys=True,image_only=True),
        EnsureChannelFirstd(keys=['image', 'label'], allow_missing_keys=True),
        NormalizeIntensityd(keys=['image'], allow_missing_keys=False),
        EnsureTyped(keys=['image', 'label'], allow_missing_keys=True),
        RandGridDistortiond(keys=['image', 'label'], allow_missing_keys=True, mode=['bilinear', 'nearest'],
                            distort_limit=0.1, device=torch.device('cuda')),
        RandSpatialCropd(keys=['image', 'label'], allow_missing_keys=True,
                         roi_size=cfg['TRAIN']['PATCH_SIZE'], random_size=False),
    ])

    val_aug = Compose([
        LoadImaged(keys=['image', 'label'], allow_missing_keys=True,image_only=True),
        EnsureChannelFirstd(keys=['image', 'label'], allow_missing_keys=True),
        NormalizeIntensityd(keys=['image'], allow_missing_keys=False),
        EnsureTyped(keys=['image', 'label'], allow_missing_keys=True),
    ])

    save_root_path = './experiments'
    image_root, num_classes, class_names, affine, = prepare_experiment(args.task)
    save_dir, metric_savedir, infer_save_dir, vis_save_dir = makedirs(args.task, full_exp_name, save_root_path)
    data_pipeline = TrainValDataPipeline(image_root, label_ratio=ratio, random_seed=seed)
    trainset, unlabeled_set, valset = data_pipeline.get_dataset(train_aug, val_aug, cache_dataset=False)
    train_sampler = RandomSampler(trainset)
    unlabeled_sampler = RandomSampler(unlabeled_set)
    val_sampler = RandomSampler(valset)    # define tasks-specific information
    # define devices and loaders
    train_loader = DataLoader(trainset, batch_size=batch_size,  num_workers=args.ncpu,
                              sampler=train_sampler, persistent_workers=True)

    unlabeled_loader = DataLoader(unlabeled_set, batch_size=batch_size, num_workers=args.ncpu,
                                  sampler=unlabeled_sampler, persistent_workers=True)
    val_loader = DataLoader(valset, batch_size=1, shuffle=False, sampler=val_sampler)
    # print("val_loader",val_loader)

    # initialize metrics containers
    train_losses_A, val_losses_A = [], []
    train_losses_B, val_losses_B = [],[]
    accuracies_A, accuracies_B = [],[]
    learning_rates_A, learning_rates_B = [],[]

    # define models
    modelA = SemiSupervisedContrastiveSegmentationModelA(cfg, num_classes=num_classes, amp=args.mixed)
    modelB = SemiSupervisedContrastiveSegmentationModelB(cfg, num_classes=num_classes, amp=args.mixed)

    if args.pretrain_ckpt:
        modelA.load_networks(args.pretrain_ckpt, resume_training=True)
        modelB.load_networks(args.pretrain_ckpt, resume_training=True)
        print('Checkpoint {} loaded'.format(args.pretrain_ckpt))
    modelA.initialize_metric_meter(class_names)
    modelB.initialize_metric_meter(class_names)

    if args.wandb and dist.get_rank() == 0:
        wandb.init(project=cfg['PROJECT'], entity=args.entity, reinit=True, name=cfg['EXP_NAME'])
        wandb.config.update(cfg)

    # starts training
    print('Start training, please wait...')
    epoch_manager = EpochManager()
    start_time = time.time()
    for epoch in range(num_epochs):
        epoch_manager.update_epoch(epoch)
        epoch_start_time = time.time()
        tbar = tqdm.tqdm(range(len(unlabeled_loader))) if args.verbose else range(len(unlabeled_loader))
        # print("Epoch {}/{}, current lr {}".format(epoch + 1, num_epochs, model.optimizer.param_groups[0]['lr']))
        print("Epoch {}/{}, modelA current lr {}, modelB current lr {}".format(epoch + 1, num_epochs,
                                                                               modelA.optimizer.param_groups[0]['lr'],
                                                                               modelB.optimizer.param_groups[0]['lr']))
        modelA.train()
        modelB.train()
        data_loader = iter(zip(cycle(train_loader), unlabeled_loader))
        for step in tbar:
            batch_data_labeled, batch_data_unlabeled = next(data_loader)
            modelA.set_input(batch_data_labeled, batch_data_unlabeled)
            modelB.set_input(batch_data_labeled, batch_data_unlabeled)
            # forward and backward
            with torch.no_grad():
                modelA.forward_semi()
                pseudo_labels_A = {'pred_l': modelA.pseudo_labels_l, 'pred_u': modelA.pseudo_labels_u}
                pseudo_labels_A1 = {'pred_l': modelA.pseudo_labels_l1, 'pred_u': modelA.pseudo_labels_u1}
                modelB.forward_semi()
                pseudo_labels_B = {'pred_l': modelB.pseudo_labels_l ,'pred_u': modelB.pseudo_labels_u}
                pseudo_labels_B1 = {'pred_l': modelB.pseudo_labels_l1, 'pred_u': modelB.pseudo_labels_u1}
            modelA.optimize_parameters_cross_supervision(epoch, pseudo_labels_B, pseudo_labels_B1)
            torch.cuda.empty_cache()
            modelB.optimize_parameters_cross_supervision(epoch, pseudo_labels_A, pseudo_labels_A1)
            torch.cuda.empty_cache()
            statsA = modelA.update_loss_meter(print=False)  # update the training loss meter
            statsB = modelB.update_loss_meter(print=False)  # update the training loss meter

            if args.verbose:
                tbar.set_postfix_str(statsA)  # set progress bar postfix
                tbar.set_postfix_str(statsB)  # set progress bar postfix

        if not args.verbose:
            modelA.update_loss_meter(print=True)
            modelB.update_loss_meter(print=True)
        if args.wandb and dist.get_rank() == 0:
            modelA.log_train_loss(step=epoch + 1)
            modelB.log_train_loss(step=epoch + 1)
        # After each epoch, record the metrics
        train_losses_A.append(modelA.Get_train_loss())
        train_losses_B.append(modelB.Get_train_loss())

        learning_rates_A.append(modelA.optimizer.param_groups[0]['lr'])
        learning_rates_B.append(modelB.optimizer.param_groups[0]['lr'])

        modelA.scheduler.step()
        modelB.scheduler.step()

        # evaluation loop
        if (epoch + 1) % args.eval_interval == 0 or (epoch + 1) > num_epochs - 2:
            print('Evaluating, plz wait...')
            modelA.eval()
            modelB.eval()
            val_loader = tqdm.tqdm(val_loader) if args.verbose else val_loader
            for step, batch_data in enumerate(val_loader):
                modelA.set_test_input1(batch_data)
                modelB.set_test_input1(batch_data)
                modelA.evaluate_one_step(True if (epoch + 1) % args.save_interval == 0 else False,
                                        infer_save_dir, affine, patch_based_inference=True)
                modelB.evaluate_one_step(True if (epoch + 1) % args.save_interval == 0 else False,
                                        infer_save_dir, affine, patch_based_inference=True)

            current_metricA = modelA.metric_meter.pop_mean_metric()['dice']
            current_metricB = modelB.metric_meter.pop_mean_metric()['dice']

            print("model.metric_meter_A",modelA.metric_meter)
            print("model.metric_meter_B",modelB.metric_meter)
            print("current_metric_A",current_metricA)
            print("current_metric_B",current_metricB)

            if args.wandb and dist.get_rank() == 0:
                modelA.log_val_loss(step=epoch + 1)
                modelB.log_val_loss(step=epoch + 1)


                modelA.log_scaler('val/val_metric_mean', current_metricA, step=epoch + 1)
                modelB.log_scaler('val/val_metric_mean', current_metricB, step=epoch + 1)

            modelA.metric_meter.report(print_stats=True)  
            modelB.metric_meter.report(print_stats=True)  

            modelA.metric_meter.save(metric_savedir, '{}_Epoch_{}_A.csv'.format(full_exp_name, epoch + 1))
            modelB.metric_meter.save(metric_savedir, '{}_Epoch_{}_B.csv'.format(full_exp_name, epoch + 1))
            # After each evaluation, record the validation loss and metric (accuracy, Dice, etc.)
            val_losses_A.append(modelA.Get_val_loss())
            val_losses_B.append(modelB.Get_val_loss())
            accuracies_A.append(modelA.metric_meter.pop_mean_metric()['dice'])
            accuracies_B.append(modelB.metric_meter.pop_mean_metric()['dice'])

            modelA.metric_meter.initialization()
            modelB.metric_meter.initialization()
            modelA.val_loss.initialization()
            modelB.val_loss.initialization()
            if (epoch + 1) % args.eval_interval == 0 or (epoch + 1) > num_epochs - 5:
                if current_metricA >= current_metricB:
                    print(
                        f"Epoch {epoch+1}: Model A has higher Dice ({current_metricA} >= {current_metricB}). Saving Model A...")
                    modelA.save_networks(epoch, save_dir)
                    modelA.save_networks_pth(epoch, save_dir)
                else:
                    print(
                        f"Epoch {epoch+1}: Model B has higher Dice ({current_metricB} > {current_metricA}). Saving Model B...")
                    modelB.save_networks(epoch, save_dir)
                    modelB.save_networks_pth(epoch, save_dir)
                modelA.save_networks_pth_A(epoch, save_dir)
                modelB.save_networks_pth_B(epoch, save_dir)
            # early_stopping_A(current_metricA, modelA, epoch)
            # early_stopping_B(current_metricB, modelB, epoch)
            # if early_stopping_A.early_stop:
            #     print(
            #         f"Early stopping triggered for Model A at epoch {epoch + 1}. Best epoch: {early_stopping_A.best_epoch}")
            #     break
            # if early_stopping_B.early_stop:
            #     print(
            #         f"Early stopping triggered for Model B at epoch {epoch + 1}. Best epoch: {early_stopping_B.best_epoch}")
            #     break

        epoch_end_time = time.time()
        epoch_time_taken = epoch_end_time - epoch_start_time
        print(f"Epoch {epoch + 1} took: {epoch_time_taken} seconds")
    end_time = time.time()
    total_training_time = end_time - start_time
    print(f"Total training time: {total_training_time} seconds")

    loss_types = ['train_seg_loss_mean', 'train_cps_l_loss_mean', 'train_cps_u_loss_mean','train_contrastive_l_loss_mean', 'train_contrastive_u_loss_mean',
                  'train_cosine_l_loss_mean', 'train_cosine_u_loss_mean','train_cps_l_other_mean','train_cps_u_other_mean']
    save_train_photo = '/root/autodl-tmp/DBCPS/DBCPS/experiments/photo/train_loss_plot.png'
    plot_train_losses(train_losses_A, train_losses_B, loss_types, save_train_photo)
    val_save_path = '/root/autodl-tmp/DBCPS/DBCPS/experiments/photo/val_loss_plot.png'
    plot_val_losses(val_losses_A, val_losses_B, val_save_path)
    accuracy_save_path = '/root/autodl-tmp/DBCPS/DBCPS/experiments/photo/accuracy_plot.png'
    plot_accuracy(accuracies_A, accuracies_B, accuracy_save_path)

if __name__ == '__main__':
    main()
